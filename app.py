import json
import numpy as np
import faiss
import streamlit as st
from sentence_transformers import SentenceTransformer

# ---------------------------
# T·∫¢I M√î H√åNH E5-BASE
# ---------------------------
model = SentenceTransformer("intfloat/multilingual-e5-base", device="cpu")  # Ch·∫°y tr√™n GPU Apple Silicon (MPS)

# ---------------------------
# H√ÄM T·∫†O EMBEDDING BATCH S·ª¨ D·ª§NG E5-BASE
# ---------------------------
def get_embedding_batch(texts):
    texts = [f"query: {t.lower()}" for t in texts]  # ƒê·ªãnh d·∫°ng theo y√™u c·∫ßu c·ªßa E5
    embeddings = model.encode(texts, normalize_embeddings=True, batch_size=16)  # Batch x·ª≠ l√Ω nhanh h∆°n
    return np.array(embeddings, dtype="float32")  # Chuy·ªÉn v·ªÅ numpy array

# ---------------------------
# ƒê·ªåC D·ªÆ LI·ªÜU Q&A T·ª™ FILE chatbot.json
# ---------------------------
data_file = "chatbot.json"
with open(data_file, "r", encoding="utf-8") as f:
    qa_data = json.load(f)

# ---------------------------
# ƒê·ªåC EMBEDDING T·ª™ FILE HO·∫∂C T·∫†O M·ªöI
# ---------------------------
embedding_file = "embedding_data_e5.json"

try:
    with open(embedding_file, "r", encoding="utf-8") as f:
        embedding_data = json.load(f)
    print("‚úÖ Loaded precomputed embeddings.")
except FileNotFoundError:
    print("üöÄ Embedding file not found. Creating new embeddings...")
    questions_list = [q for qs in qa_data.values() for q in qs]  # L·∫•y t·∫•t c·∫£ c√¢u h·ªèi
    embeddings_array = get_embedding_batch(questions_list)  # Encode to√†n b·ªô danh s√°ch c√¢u h·ªèi
    embedding_data = {q: embeddings_array[i].tolist() for i, q in enumerate(questions_list)}

    # L∆∞u v√†o file JSON
    with open(embedding_file, "w", encoding="utf-8") as f:
        json.dump(embedding_data, f, ensure_ascii=False, indent=4)

# ---------------------------
# CHUY·ªÇN EMBEDDING T·ª™ JSON SANG NUMPY ARRAY
# ---------------------------
questions_list = list(embedding_data.keys())
embeddings_list = [embedding_data[question] for question in questions_list]
embeddings_array = np.array(embeddings_list, dtype="float32")

# ---------------------------
# KI·ªÇM TRA K√çCH TH∆Ø·ªöC EMBEDDING (E5-BASE L√Ä 768)
# ---------------------------
if embeddings_array.shape[1] != 768:
    print(f"‚ùå L·ªói: M√¥ h√¨nh e5-base y√™u c·∫ßu embedding 768 chi·ªÅu, nh∆∞ng d·ªØ li·ªáu c√≥ {embeddings_array.shape[1]} chi·ªÅu!")
    exit()

# ---------------------------
# CHU·∫®N H√ìA VECTORS (L2 normalization)
# ---------------------------
faiss.normalize_L2(embeddings_array)

# ---------------------------
# X√ÇY D·ª∞NG FAISS INDEX
# ---------------------------
d = 768  # E5-base c√≥ 768 chi·ªÅu, kh√¥ng ph·∫£i 1024 nh∆∞ bge-m3
index = faiss.IndexFlatIP(d)  # D√πng inner product (IP) v√¨ ƒë√£ normalize
index.add(embeddings_array)  # Th√™m embedding v√†o FAISS

# T·∫°o mapping t·ª´ ch·ªâ s·ªë FAISS sang c√¢u h·ªèi
index_to_question = {i: questions_list[i] for i in range(len(questions_list))}

# ---------------------------
# H√ÄM X·ª¨ L√ù TRUY V·∫§N Q&A S·ª¨ D·ª§NG FAISS
# ---------------------------
def answer_query_faiss(user_query, similarity_threshold=0.85):
    query_emb = get_embedding_batch([user_query])  # Encode batch (ch·ªâ 1 c√¢u)
    
    k = 1  # L·∫•y 1 k·∫øt qu·∫£ t·ªët nh·∫•t
    distances, indices = index.search(query_emb, k)
    
    best_score = distances[0][0]
    best_index = indices[0][0]

    if best_score < similarity_threshold:
        return "Ch√∫ng t√¥i ch∆∞a hi·ªÉu c√¢u h·ªèi c·ªßa b·∫°n.", None, None

    best_question = index_to_question[best_index]
    
    for key, value in qa_data.items():
        if best_question in value:
            return key, best_question, best_score  # **Tr·∫£ v·ªÅ c√¢u tr·∫£ l·ªùi, c√¢u h·ªèi t√¨m th·∫•y v√† ƒë·ªô t∆∞∆°ng ƒë·ªìng**
    
    return "C√¢u h·ªèi kh√¥ng kh·ªõp v·ªõi d·ªØ li·ªáu, vui l√≤ng th·ª≠ l·∫°i!", None, None

# ---------------------------
# STREAMLIT UI
# ---------------------------
st.title("Chatbot tra c·ª©u th√¥ng tin c√°c k·ª≥ thi c·ªßa Empire")

user_query = st.text_input("B·∫°n h·ªèi:")

if user_query:
    answer, matched_question, similarity = answer_query_faiss(user_query)

    if matched_question:

        if isinstance(answer, str) and answer.lower().endswith((".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp")):
            st.image(answer, caption="K·∫øt qu·∫£ t√¨m th·∫•y", use_container_width=True)
        else:
            st.markdown(f"**Tr·∫£ l·ªùi:** \n\n{answer}")
    else:
        st.markdown(f"**Tr·∫£ l·ªùi:** \n\n{answer}")

