import json
import numpy as np
import faiss
import streamlit as st
from sentence_transformers import SentenceTransformer

# ğŸŸ¢ Táº£i mÃ´ hÃ¬nh embedding tiáº¿ng Viá»‡t (768 chiá»u)
model = SentenceTransformer("VoVanPhuc/sup-SimCSE-VietNamese-phobert-base", device="cpu")  

# ğŸŸ¢ HÃ€M Táº O EMBEDDING
def get_embedding_batch(texts):
    texts = [t.lower() for t in texts]  # Chuyá»ƒn vá» lowercase
    embeddings = model.encode(texts, normalize_embeddings=True, batch_size=16)  
    return np.array(embeddings, dtype="float32")  

# ğŸŸ¢ Äá»ŒC Dá»® LIá»†U Q&A
data_file = "chatbot.json"
with open(data_file, "r", encoding="utf-8") as f:
    qa_data = json.load(f)

embedding_file = "embedding_data_vn.json"

# ğŸŸ¢ LOAD HOáº¶C Táº O EMBEDDINGS
try:
    with open(embedding_file, "r", encoding="utf-8") as f:
        embedding_data = json.load(f)
    print("âœ… Loaded precomputed embeddings.")
except FileNotFoundError:
    print("ğŸš€ Embedding file not found. Creating new embeddings...")
    questions_list = [q for qs in qa_data.values() for q in qs]  
    embeddings_array = get_embedding_batch(questions_list)  
    embedding_data = {q: embeddings_array[i].tolist() for i, q in enumerate(questions_list)}

    with open(embedding_file, "w", encoding="utf-8") as f:
        json.dump(embedding_data, f, ensure_ascii=False, indent=4)

# ğŸŸ¢ CHUYá»‚N EMBEDDING Vá»€ NUMPY ARRAY
questions_list = list(embedding_data.keys())
embeddings_list = [embedding_data[question] for question in questions_list]
embeddings_array = np.array(embeddings_list, dtype="float32")

# âŒ Kiá»ƒm tra lá»—i kÃ­ch thÆ°á»›c vector (pháº£i lÃ  768)
if embeddings_array.shape[1] != 768:
    print(f"âŒ Lá»—i: MÃ´ hÃ¬nh `sup-SimCSE-VietNamese-phobert-base` yÃªu cáº§u embedding 768 chiá»u, nhÆ°ng dá»¯ liá»‡u cÃ³ {embeddings_array.shape[1]} chiá»u!")
    exit()

# ğŸŸ¢ CHUáº¨N HÃ“A & FAISS INDEX
faiss.normalize_L2(embeddings_array)

d = 768  # âš ï¸ Cáº¬P NHáº¬T Láº I KÃCH THÆ¯á»šC CHO FAISS
index = faiss.IndexFlatIP(d)  
index.add(embeddings_array)  

index_to_question = {i: questions_list[i] for i in range(len(questions_list))}

# ğŸŸ¢ HÃ€M Xá»¬ LÃ TRUY Váº¤N
def answer_query_faiss(user_query, similarity_threshold=0.5):
    query_emb = get_embedding_batch([user_query])  
    k = 1  # âš ï¸ CHá»ˆ Láº¤Y CÃ‚U Tá»T NHáº¤T
    distances, indices = index.search(query_emb, k)

    best_score = distances[0][0]
    best_index = indices[0][0]

    if best_score < similarity_threshold:
        return "ChÃºng tÃ´i chÆ°a hiá»ƒu cÃ¢u há»i cá»§a báº¡n.", None, None

    best_question = index_to_question[best_index]
    
    for key, value in qa_data.items():
        if best_question in value:
            return key, best_question, best_score  
    
    return "CÃ¢u há»i khÃ´ng khá»›p vá»›i dá»¯ liá»‡u, vui lÃ²ng thá»­ láº¡i!", None, None

# ğŸŸ¢ STREAMLIT UI
st.title("Chatbot tra cá»©u thÃ´ng tin cÃ¡c ká»³ thi cá»§a Empire")

user_query = st.text_input("Báº¡n há»i:")

if user_query:
    answer, matched_question, similarity = answer_query_faiss(user_query)

    if matched_question:
        if isinstance(answer, str) and answer.lower().endswith((".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp")):
            st.image(answer, caption="Káº¿t quáº£ tÃ¬m tháº¥y", use_container_width=True)
        else:
            st.markdown(f"**Tráº£ lá»i:** \n\n{answer}")
    else:
        st.markdown(f"**Tráº£ lá»i:** \n\n{answer}")
