import json
import numpy as np
import faiss
import streamlit as st
from sentence_transformers import SentenceTransformer
from unidecode import unidecode  # ThÆ° viá»‡n bá» dáº¥u tiáº¿ng Viá»‡t

# ---------------------------
# 1ï¸âƒ£ Táº¢I MÃ” HÃŒNH E5-BASE
# ---------------------------
model = SentenceTransformer("intfloat/multilingual-e5-base", device="cpu")  # Cháº¡y trÃªn CPU

# ---------------------------
# 2ï¸âƒ£ HÃ€M Táº O EMBEDDING BATCH
# ---------------------------
def get_embedding_batch(texts):
    texts = [f"query: {t.lower()}" for t in texts]  # Äá»‹nh dáº¡ng theo yÃªu cáº§u cá»§a E5
    embeddings = model.encode(texts, normalize_embeddings=True, batch_size=16)  # Batch xá»­ lÃ½ nhanh hÆ¡n
    return np.array(embeddings, dtype="float32")  # Chuyá»ƒn vá» numpy array

# ---------------------------
# 3ï¸âƒ£ Äá»ŒC Dá»® LIá»†U Q&A Tá»ª FILE chatbot.json
# ---------------------------
data_file = "chatbot.json"
with open(data_file, "r", encoding="utf-8") as f:
    qa_data = json.load(f)

# ---------------------------
# 4ï¸âƒ£ Xá»¬ LÃ EMBEDDING: LÆ¯U Cáº¢ CÃ‚U Há»ŽI CÃ“ Dáº¤U VÃ€ KHÃ”NG Dáº¤U
# ---------------------------
embedding_file = "embedding_data_e5.json"

try:
    with open(embedding_file, "r", encoding="utf-8") as f:
        embedding_data = json.load(f)
    print("âœ… Loaded precomputed embeddings.")
except FileNotFoundError:
    print("ðŸš€ Embedding file not found. Creating new embeddings...")
    
    # Láº¥y danh sÃ¡ch cÃ¢u há»i cÃ³ dáº¥u vÃ  táº¡o báº£n khÃ´ng dáº¥u
    questions_list = [q for qs in qa_data.values() for q in qs]  
    questions_list_no_accent = [unidecode(q) for q in questions_list]  

    # Gá»™p cáº£ hai danh sÃ¡ch vÃ o FAISS
    all_questions = questions_list + questions_list_no_accent  
    embeddings_array = get_embedding_batch(all_questions)  

    # LÆ°u vÃ o dictionary
    embedding_data = {q: embeddings_array[i].tolist() for i, q in enumerate(all_questions)}

    # LÆ°u file JSON
    with open(embedding_file, "w", encoding="utf-8") as f:
        json.dump(embedding_data, f, ensure_ascii=False, indent=4)

# ---------------------------
# 5ï¸âƒ£ CHUYá»‚N EMBEDDING Tá»ª JSON SANG NUMPY ARRAY
# ---------------------------
questions_list = list(embedding_data.keys())
embeddings_list = [embedding_data[q] for q in questions_list]
embeddings_array = np.array(embeddings_list, dtype="float32")

# ---------------------------
# 6ï¸âƒ£ KIá»‚M TRA KÃCH THÆ¯á»šC EMBEDDING
# ---------------------------
if embeddings_array.shape[1] != 768:
    print(f"âŒ Lá»—i: MÃ´ hÃ¬nh e5-base yÃªu cáº§u embedding 768 chiá»u, nhÆ°ng dá»¯ liá»‡u cÃ³ {embeddings_array.shape[1]} chiá»u!")
    exit()

# ---------------------------
# 7ï¸âƒ£ CHUáº¨N HÃ“A VECTORS VÃ€ XÃ‚Y Dá»°NG FAISS INDEX
# ---------------------------
faiss.normalize_L2(embeddings_array)
d = 768  # E5-base cÃ³ 768 chiá»u
index = faiss.IndexFlatIP(d)  # DÃ¹ng inner product (IP) vÃ¬ Ä‘Ã£ normalize
index.add(embeddings_array)  # ThÃªm embedding vÃ o FAISS

# Mapping chá»‰ sá»‘ FAISS sang cÃ¢u há»i
index_to_question = {i: questions_list[i] for i in range(len(questions_list))}

# ---------------------------
# 8ï¸âƒ£ HÃ€M Xá»¬ LÃ TRUY Váº¤N Q&A Sá»¬ Dá»¤NG FAISS
# ---------------------------
def answer_query_faiss(user_query, similarity_threshold=0.2):
    """Xá»­ lÃ½ truy váº¥n tá»« ngÆ°á»i dÃ¹ng, há»— trá»£ cáº£ cÃ¢u cÃ³ dáº¥u vÃ  khÃ´ng dáº¥u."""
    user_query_no_accent = unidecode(user_query)  # Loáº¡i bá» dáº¥u tiáº¿ng Viá»‡t
    
    # Embed cáº£ cÃ¢u há»i gá»‘c vÃ  khÃ´ng dáº¥u
    query_emb = get_embedding_batch([user_query, user_query_no_accent])  

    k = 1  # Láº¥y káº¿t quáº£ tá»‘t nháº¥t
    distances, indices = index.search(query_emb, k)

    best_score = max(distances[0][0], distances[1][0])  # Chá»n Ä‘iá»ƒm sá»‘ cao nháº¥t
    best_index = indices[0][0] if distances[0][0] > distances[1][0] else indices[1][0]

    if best_score < similarity_threshold:
        return "ChÃºng tÃ´i chÆ°a hiá»ƒu cÃ¢u há»i cá»§a báº¡n.", None, None

    best_question = index_to_question[best_index]
    
    for key, value in qa_data.items():
        if best_question in value:
            return key, best_question, best_score  # Tráº£ vá» cÃ¢u tráº£ lá»i, cÃ¢u há»i tÃ¬m tháº¥y vÃ  Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng
    
    return "CÃ¢u há»i khÃ´ng khá»›p vá»›i dá»¯ liá»‡u, vui lÃ²ng thá»­ láº¡i!", None, None

# ---------------------------
# 9ï¸âƒ£ STREAMLIT UI
# ---------------------------
st.title("Chatbot tra cá»©u thÃ´ng tin cÃ¡c ká»³ thi cá»§a Empire")

user_query = st.text_input("Báº¡n há»i:")

if user_query:
    answer, matched_question, similarity = answer_query_faiss(user_query)

    if matched_question:
        if isinstance(answer, str) and answer.lower().endswith((".jpg", ".jpeg", ".png", ".gif", ".bmp", ".webp")):
            st.image(answer, caption="Káº¿t quáº£ tÃ¬m tháº¥y", use_container_width=True)
        else:
            st.markdown(f"**Tráº£ lá»i:** \n\n{answer}")
    else:
        st.markdown(f"**Tráº£ lá»i:** \n\n{answer}")
